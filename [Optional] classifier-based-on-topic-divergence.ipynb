{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":118082,"databundleVersionId":14294892,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"############################################################\n# 0. IMPORTS\n############################################################\nimport numpy as np\nimport pandas as pd\nimport os, json, random\nfrom tqdm.auto import tqdm\nimport lightgbm as lgb\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import NMF\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.model_selection import StratifiedKFold\n\n############################################################\n# 1. LOAD DATA\n############################################################\ntrain_df = pd.read_json(\"/kaggle/input/da5401-2025-data-challenge/train_data.json\", lines=False)\ntest_df  = pd.read_json(\"/kaggle/input/da5401-2025-data-challenge/test_data.json\", lines=False)\n\nwith open(\"/kaggle/input/da5401-2025-data-challenge/metric_names.json\") as f:\n    metric_list = json.load(f)\n\nmetric_emb = np.load(\"/kaggle/input/da5401-2025-data-challenge/metric_name_embeddings.npy\")\n\ntrain_df[\"score\"] = train_df[\"score\"].astype(float)\ntrain_df.fillna(\"\", inplace=True)\ntest_df.fillna(\"\", inplace=True)\n\nprint(\"Step 1 done\")\n############################################################\n# 2. BUILD FULL TEXT\n############################################################\ndef build_full_text(df):\n    return (\n        df[\"system_prompt\"].fillna(\"\") + \" \" +\n        df[\"user_prompt\"].fillna(\"\") + \" \" +\n        df[\"response\"].fillna(\"\")\n    )\n\ntrain_df[\"full_text\"] = build_full_text(train_df)\ntest_df[\"full_text\"]  = build_full_text(test_df)\n\nprint(\"Step 2 done\")\n############################################################\n# 3. SBERT (LABSE) EMBEDDINGS + CACHING\n############################################################\ntrain_cache = \"/kaggle/working/labse_train.npy\"\ntest_cache  = \"/kaggle/working/labse_test.npy\"\n\nif os.path.exists(train_cache) and os.path.exists(test_cache):\n    print(\"Loading cached embeddings...\")\n    X_train_sbert = np.load(train_cache)\n    X_test_sbert  = np.load(test_cache)\nelse:\n    print(\"Computing LaBSE embeddings...\")\n    model = SentenceTransformer(\"sentence-transformers/LaBSE\")\n\n    X_train_sbert = model.encode(\n        train_df[\"full_text\"].tolist(),\n        batch_size=32,\n        show_progress_bar=True\n    )\n    X_test_sbert = model.encode(\n        test_df[\"full_text\"].tolist(),\n        batch_size=32,\n        show_progress_bar=True\n    )\n\n    np.save(train_cache, X_train_sbert)\n    np.save(test_cache, X_test_sbert)\n\nprint(\"Train shape:\", X_train_sbert.shape)\nprint(\"Test shape :\", X_test_sbert.shape)\n\n############################################################\n# 4. NEGATIVE SAMPLING (WRONG METRIC → SCORE 0)\n############################################################\ndef negative_sampling(df, metric_list, k=1):\n    high = df[df[\"score\"] >= 8]\n    new_rows = []\n\n    for _, row in tqdm(high.iterrows(), total=len(high)):\n        current_metric = row[\"metric_name\"]\n        candidates = [m for m in metric_list if m != current_metric]\n\n        chosen = random.sample(candidates, k)\n\n        for cm in chosen:\n            new_row = row.copy()\n            new_row[\"metric_name\"] = cm\n            new_row[\"score\"] = 0.0\n            new_rows.append(new_row)\n\n    return pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n\ntrain_aug = negative_sampling(train_df, metric_list, k=1)\ntrain_aug = train_aug.sample(frac=1).reset_index(drop=True)\nprint(\"Step 4 done\")\n############################################################\n# 5. ALIGN EMBEDDINGS WITH AUGMENTED DATA\n############################################################\norig_len = len(train_df)\n\nrow_map = []\nfor idx, row in train_aug.iterrows():\n    if row[\"score\"] == 0:\n        row_map.append(random.randint(0, orig_len - 1))\n    else:\n        row_map.append(idx)\n\nX_train_final = X_train_sbert[row_map]\ny = train_aug[\"score\"].astype(int).values\nprint(\"Step 5 done\")\n############################################################\n# 6. TOPIC DIVERGENCE\n############################################################\ndef compute_topic_div(train_df, test_df):\n    all_text = pd.concat([\n        train_df[\"user_prompt\"], train_df[\"response\"],\n        test_df[\"user_prompt\"], test_df[\"response\"]\n    ]).fillna(\"\")\n\n    tfidf = TfidfVectorizer(max_features=4000, min_df=3, stop_words=\"english\")\n    X = tfidf.fit_transform(all_text)\n\n    nmf = NMF(n_components=20, init=\"nndsvda\", random_state=42)\n    topics = nmf.fit_transform(X)\n\n    n_tr = len(train_df)\n    n_ts = len(test_df)\n\n    P_tr = topics[:n_tr]\n    R_tr = topics[n_tr:n_tr*2]\n\n    P_ts = topics[n_tr*2:n_tr*2+n_ts]\n    R_ts = topics[n_tr*2+n_tr*2-n_ts : n_tr*2+n_ts]\n\n    div_tr = 1 - np.diag(cosine_similarity(P_tr, R_tr))\n    div_ts = 1 - np.diag(cosine_similarity(P_ts, R_ts))\n\n    return div_tr, div_ts\n\ntopic_div_train, topic_div_test = compute_topic_div(train_aug, test_df)\n\n############################################################\n# 7. MODEL A — MULTICLASS CLASSIFIER (EMBEDDINGS)\n############################################################\nparams_cls = {\n    \"objective\": \"multiclass\",\n    \"num_class\": 11,\n    \"metric\": \"multi_logloss\",\n    \"learning_rate\": 0.04,\n    \"num_leaves\": 48,\n    \"feature_fraction\": 0.8,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 1,\n    \"seed\": 42,\n}\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\noof_cls = np.zeros((len(train_aug), 11))\ntest_cls = np.zeros((len(test_df), 11))\n\nfor tr, va in skf.split(X_train_final, y):\n    dtr = lgb.Dataset(X_train_final[tr], label=y[tr])\n    dval = lgb.Dataset(X_train_final[va], label=y[va])\n\n    model = lgb.train(params_cls, dtr, 600,\n                      valid_sets=[dval],\n                      verbose_eval=False,\n                      early_stopping_rounds=50)\n\n    oof_cls[va] = model.predict(X_train_final[va])\n    test_cls += model.predict(X_test_sbert) / 5\n\npred_cls = (oof_cls * np.arange(11)).sum(axis=1)\npred_cls_test = (test_cls * np.arange(11)).sum(axis=1)\nprint(\"STEP 7 DONE\")\n############################################################\n# 8. MODEL B — TOPIC DIVERGENCE REGRESSOR\n############################################################\nparams_div = {\n    \"objective\": \"regression\",\n    \"metric\": \"rmse\",\n    \"learning_rate\": 0.04,\n    \"num_leaves\": 20,\n    \"seed\": 42,\n}\n\noof_div = np.zeros(len(train_aug))\ntest_div = np.zeros(len(test_df))\n\nfor tr, va in skf.split(topic_div_train.reshape(-1,1), y):\n    dtr = lgb.Dataset(topic_div_train[tr].reshape(-1,1), label=y[tr])\n    dval = lgb.Dataset(topic_div_train[va].reshape(-1,1), label=y[va])\n\n    model = lgb.train(params_div, dtr, 300,\n                      valid_sets=[dval],\n                      verbose_eval=False,\n                      early_stopping_rounds=50)\n\n    oof_div[va] = model.predict(topic_div_train[va].reshape(-1,1))\n    test_div += model.predict(topic_div_test.reshape(-1,1)) / 5\n\noof_div_scaled  = 10 * (1 - oof_div / oof_div.max())\ntest_div_scaled = 10 * (1 - test_div / test_div.max())\nprint(\"Syep 8 done\")\n############################################################\n# 9. ENSEMBLE\n############################################################\nfinal_oof  = 0.65 * pred_cls + 0.35 * oof_div_scaled\nfinal_test = 0.65 * pred_cls_test + 0.35 * test_div_scaled\nfinal_test = np.clip(final_test, 0, 10)\n\n############################################################\n# 10. SUBMISSION\n############################################################\nsubmission = pd.DataFrame({\n    \"ID\": np.arange(1, len(test_df)+1),\n    \"score\": final_test\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Saved submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:03:39.776947Z","iopub.execute_input":"2025-11-19T12:03:39.777272Z","iopub.status.idle":"2025-11-19T12:06:09.351096Z","shell.execute_reply.started":"2025-11-19T12:03:39.777246Z","shell.execute_reply":"2025-11-19T12:06:09.350275Z"}},"outputs":[{"name":"stdout","text":"Step 1 done\nStep 2 done\nComputing LaBSE embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12d15d95ebff4844a6e7380a43b00c01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47c31f87b53144dfbb3ee02f68a0a7dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf29fff14bd3469f8b06e893ca87cd89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2d8f19596cf443a9661d397dcbd2037"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/804 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2c991fa391848448503eb0f9bb3b90f"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.88G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32d0a07fefe547eab9e73a77339a2b9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/397 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ec86457cf104b9490ec25eee847f18d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15120ed43ef2415290e3e60e7fea9218"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7876ed6c481545288e5d1e98f8e091c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"545952c69f0445ad8308d0cc24124c57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbe78394c547490ba63ce4274884123d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/114 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ca09c6387e546da91fc1e19eecccb76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"2_Dense/model.safetensors:   0%|          | 0.00/2.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93f792b603014d5cbd77bf75f86cf5e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"2_Dense/pytorch_model.bin:   0%|          | 0.00/2.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6596929c7ff4e7290abbacf3cb4e702"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9f816a68c984969a21a08ebf9cd8fe0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/114 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"477afb83186d407f9e375a1b8822fa5a"}},"metadata":{}},{"name":"stdout","text":"Train shape: (5000, 768)\nTest shape : (3638, 768)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4825 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf7340d3782945fa9db9d296102548c4"}},"metadata":{}},{"name":"stdout","text":"Step 4 done\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/2628952599.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mrow_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mX_train_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_sbert\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_map\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_aug\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step 5 done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: index 5003 is out of bounds for axis 0 with size 5000"],"ename":"IndexError","evalue":"index 5003 is out of bounds for axis 0 with size 5000","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"# ============================================\n# CELL 1 — Imports, Setup, Seed\n# ============================================\n\nimport os\nimport json\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\n\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nimport torch\nfrom sentence_transformers import SentenceTransformer\n\n# Ensure reproducibility\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\n\nprint(\"Cell 1 complete — imports loaded.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:27:09.808274Z","iopub.execute_input":"2025-11-19T12:27:09.808765Z","iopub.status.idle":"2025-11-19T12:27:09.835113Z","shell.execute_reply.started":"2025-11-19T12:27:09.808738Z","shell.execute_reply":"2025-11-19T12:27:09.834397Z"}},"outputs":[{"name":"stdout","text":"Cell 1 complete — imports loaded.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================\n# CELL 2 — Load Data\n# ============================================\n\nTRAIN_PATH = \"/kaggle/input/da5401-2025-data-challenge/train_data.json\"\nTEST_PATH  = \"/kaggle/input/da5401-2025-data-challenge/test_data.json\"\nMETRIC_EMB_PATH = \"/kaggle/input/da5401-2025-data-challenge/metric_name_embeddings.npy\"\nMETRIC_NAMES_PATH = \"/kaggle/input/da5401-2025-data-challenge/metric_names.json\"\n\nprint(\"Loading JSON files...\")\n\ntrain_df = pd.read_json(TRAIN_PATH, lines=False)\ntest_df  = pd.read_json(TEST_PATH,  lines=False)\n\nwith open(METRIC_NAMES_PATH, \"r\") as f:\n    metric_list = json.load(f)\n\nmetric_embeddings = np.load(METRIC_EMB_PATH)\n\nprint(\"Train shape:\", train_df.shape)\nprint(\"Test shape :\", test_df.shape)\nprint(\"Number of metric names:\", len(metric_list))\n\n# Add original index for safe back-referencing\ntrain_df[\"orig_index\"] = np.arange(len(train_df))\n\nprint(\"Cell 2 complete — data loaded.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:29:20.735172Z","iopub.execute_input":"2025-11-19T12:29:20.735921Z","iopub.status.idle":"2025-11-19T12:29:20.985208Z","shell.execute_reply.started":"2025-11-19T12:29:20.735895Z","shell.execute_reply":"2025-11-19T12:29:20.984561Z"}},"outputs":[{"name":"stdout","text":"Loading JSON files...\nTrain shape: (5000, 5)\nTest shape : (3638, 4)\nNumber of metric names: 145\nCell 2 complete — data loaded.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================\n# CELL 3 — Build FULL TEXT for Embedding\n# ============================================\n\ndef build_full_text(df):\n    return (\n        df[\"system_prompt\"].fillna(\"\") + \" \" +\n        df[\"user_prompt\"].fillna(\"\") + \" \" +\n        df[\"response\"].fillna(\"\")\n    )\n\ntrain_df[\"full_text\"] = build_full_text(train_df)\ntest_df[\"full_text\"]  = build_full_text(test_df)\n\nprint(\"Example full_text:\")\nprint(train_df[\"full_text\"].iloc[0][:200], \"...\")\n\nprint(\"Cell 3 complete — full_text constructed.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:29:28.094396Z","iopub.execute_input":"2025-11-19T12:29:28.095160Z","iopub.status.idle":"2025-11-19T12:29:28.123295Z","shell.execute_reply.started":"2025-11-19T12:29:28.095136Z","shell.execute_reply":"2025-11-19T12:29:28.122539Z"}},"outputs":[{"name":"stdout","text":"Example full_text:\nYou are a medical assistance chatbot, and you must reject any unsafe, illegal, or unethical requests, while clearly explaining the reason for the rejection. எனக்கு கொஞ்ச நாளா வயித்துல வலிக்குது. என்  ...\nCell 3 complete — full_text constructed.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# ============================================\n# CELL 4 — LaBSE Embeddings (with caching)\n# ============================================\n\nCACHE_TRAIN = \"/kaggle/working/labse_train_embeddings.npy\"\nCACHE_TEST  = \"/kaggle/working/labse_test_embeddings.npy\"\n\nmodel = SentenceTransformer(\"sentence-transformers/LaBSE\")\n\nif os.path.exists(CACHE_TRAIN) and os.path.exists(CACHE_TEST):\n    print(\"Loading cached embeddings...\")\n    X_train_labse = np.load(CACHE_TRAIN)\n    X_test_labse  = np.load(CACHE_TEST)\n\nelse:\n    print(\"Computing LaBSE embeddings...\")\n    X_train_labse = model.encode(\n        train_df[\"full_text\"].tolist(),\n        batch_size=32,\n        show_progress_bar=True\n    )\n    np.save(CACHE_TRAIN, X_train_labse)\n\n    X_test_labse = model.encode(\n        test_df[\"full_text\"].tolist(),\n        batch_size=32,\n        show_progress_bar=True\n    )\n    np.save(CACHE_TEST, X_test_labse)\n\nprint(\"LaBSE shapes:\", X_train_labse.shape, X_test_labse.shape)\nprint(\"Cell 4 complete — embeddings ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:29:36.124763Z","iopub.execute_input":"2025-11-19T12:29:36.125070Z","iopub.status.idle":"2025-11-19T12:32:10.181930Z","shell.execute_reply.started":"2025-11-19T12:29:36.125047Z","shell.execute_reply":"2025-11-19T12:32:10.181253Z"}},"outputs":[{"name":"stdout","text":"Computing LaBSE embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a92c7da1dda24ba9847e43dee34d947e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/114 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f366839494624643a38a5e81b02dab43"}},"metadata":{}},{"name":"stdout","text":"LaBSE shapes: (5000, 768) (3638, 768)\nCell 4 complete — embeddings ready.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ============================================\n# CELL 3 — Load LaBSE (fixed name)\n# ============================================\n\nfrom sentence_transformers import SentenceTransformer\n\nlabse_model = SentenceTransformer(\"sentence-transformers/LaBSE\")\n\nprint(\"LaBSE model loaded as labse_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:59:44.684373Z","iopub.execute_input":"2025-11-19T12:59:44.684993Z","iopub.status.idle":"2025-11-19T12:59:47.593769Z","shell.execute_reply.started":"2025-11-19T12:59:44.684959Z","shell.execute_reply":"2025-11-19T12:59:47.592957Z"}},"outputs":[{"name":"stdout","text":"LaBSE model loaded as labse_model\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# ============================================\n# CELL 4 — Compute Topic Divergence Function\n# ============================================\n\ndef compute_divergence(df, col1=\"user_prompt\", col2=\"response\"):\n    \"\"\"\n    Compute topic divergence = 1 - cosine_similarity\n    using LaBSE embeddings for (user_prompt, response).\n    \"\"\"\n    print(f\"Encoding {col1}...\")\n    emb1 = labse_model.encode(\n        df[col1].fillna(\"\").tolist(),\n        batch_size=32,\n        show_progress_bar=True\n    )\n\n    print(f\"Encoding {col2}...\")\n    emb2 = labse_model.encode(\n        df[col2].fillna(\"\").tolist(),\n        batch_size=32,\n        show_progress_bar=True\n    )\n\n    cos = cosine_similarity(emb1, emb2).diagonal()\n    divergence = 1 - cos\n\n    return divergence\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:59:54.488403Z","iopub.execute_input":"2025-11-19T12:59:54.488676Z","iopub.status.idle":"2025-11-19T12:59:54.495061Z","shell.execute_reply.started":"2025-11-19T12:59:54.488657Z","shell.execute_reply":"2025-11-19T12:59:54.494243Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# ============================================\n# CELL 5 — Generate Train/Test Divergence\n# ============================================\n\nprint(\"Computing divergence for train...\")\ndiv_train = compute_divergence(train_df)\n\nprint(\"Computing divergence for test...\")\ndiv_test = compute_divergence(test_df)\n\nX_div_train = div_train.reshape(-1, 1)\ny_div_train = train_df[\"score\"].astype(float).values\n\nX_div_test = div_test.reshape(-1, 1)\n\nprint(\"Train divergence shape:\", X_div_train.shape)\nprint(\"Test divergence shape :\", X_div_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:00:02.704459Z","iopub.execute_input":"2025-11-19T13:00:02.704730Z","iopub.status.idle":"2025-11-19T13:03:26.277894Z","shell.execute_reply.started":"2025-11-19T13:00:02.704711Z","shell.execute_reply":"2025-11-19T13:03:26.277145Z"}},"outputs":[{"name":"stdout","text":"Computing divergence for train...\nEncoding user_prompt...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74bb246bb72f4bf48a501d65b530be0c"}},"metadata":{}},{"name":"stdout","text":"Encoding response...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/157 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54fc7dac9ca745a48e95c0783afb68a0"}},"metadata":{}},{"name":"stdout","text":"Computing divergence for test...\nEncoding user_prompt...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/114 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"504b4e638c7446ff93ffff73cd267681"}},"metadata":{}},{"name":"stdout","text":"Encoding response...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/114 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"422f0a2474814f14922ceed5217f7c7d"}},"metadata":{}},{"name":"stdout","text":"Train divergence shape: (5000, 1)\nTest divergence shape : (3638, 1)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# ============================================\n# CELL 6 — Train LightGBM Divergence Regressor\n# ============================================\n\nparams_div = {\n    \"objective\": \"regression\",\n    \"metric\": \"rmse\",\n    \"learning_rate\": 0.05,\n    \"num_leaves\": 16,\n    \"min_data_in_leaf\": 25,\n    \"verbosity\": -1,\n    \"seed\": 42,\n}\n\ngkf = GroupKFold(n_splits=5)\ngroups = train_df[\"metric_name\"].values\n\noof_div = np.zeros_like(y_div_train)\ntest_div_pred = np.zeros(len(test_df))\n\nprint(\"Training divergence regressor...\")\n\nfor fold, (tr_idx, val_idx) in enumerate(gkf.split(X_div_train, y_div_train, groups)):\n    print(f\"\\nFold {fold}\")\n\n    train_set = lgb.Dataset(X_div_train[tr_idx], y_div_train[tr_idx])\n    val_set   = lgb.Dataset(X_div_train[val_idx], y_div_train[val_idx])\n\n    model_div = lgb.train(\n        params_div,\n        train_set,\n        num_boost_round=500,\n        valid_sets=[val_set],\n        callbacks=[\n            lgb.early_stopping(50),\n            lgb.log_evaluation(50)\n        ]\n    )\n\n    oof_div[val_idx] = model_div.predict(X_div_train[val_idx])\n    test_div_pred += model_div.predict(X_div_test) / gkf.n_splits\n\nrmse_div = mean_squared_error(y_div_train, oof_div, squared=False)\nprint(\"\\nDivergence-only RMSE:\", rmse_div)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:03:26.279293Z","iopub.execute_input":"2025-11-19T13:03:26.279545Z","iopub.status.idle":"2025-11-19T13:03:26.402294Z","shell.execute_reply.started":"2025-11-19T13:03:26.279528Z","shell.execute_reply":"2025-11-19T13:03:26.401493Z"}},"outputs":[{"name":"stdout","text":"Training divergence regressor...\n\nFold 0\nTraining until validation scores don't improve for 50 rounds\n[50]\tvalid_0's rmse: 0.914709\nEarly stopping, best iteration is:\n[1]\tvalid_0's rmse: 0.909861\n\nFold 1\nTraining until validation scores don't improve for 50 rounds\n[50]\tvalid_0's rmse: 0.959689\nEarly stopping, best iteration is:\n[1]\tvalid_0's rmse: 0.955632\n\nFold 2\nTraining until validation scores don't improve for 50 rounds\n[50]\tvalid_0's rmse: 0.983316\nEarly stopping, best iteration is:\n[5]\tvalid_0's rmse: 0.980331\n\nFold 3\nTraining until validation scores don't improve for 50 rounds\n[50]\tvalid_0's rmse: 0.846234\nEarly stopping, best iteration is:\n[2]\tvalid_0's rmse: 0.843561\n\nFold 4\nTraining until validation scores don't improve for 50 rounds\n[50]\tvalid_0's rmse: 1.02515\nEarly stopping, best iteration is:\n[1]\tvalid_0's rmse: 1.01526\n\nDivergence-only RMSE: 0.9427769128674659\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# ============================================\n# CELL 7 — Submission\n# ============================================\n\nsubmission = pd.DataFrame({\n    \"ID\": np.arange(1, len(test_df) + 1),\n    \"score\": np.clip(test_div_pred, 0, 10)\n})\n\nsave_path = \"/kaggle/working/submission_divergence_only.csv\"\nsubmission.to_csv(save_path, index=False)\n\nprint(\"Saved:\", save_path)\nprint(submission.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:03:26.403030Z","iopub.execute_input":"2025-11-19T13:03:26.403234Z","iopub.status.idle":"2025-11-19T13:03:26.429706Z","shell.execute_reply.started":"2025-11-19T13:03:26.403218Z","shell.execute_reply":"2025-11-19T13:03:26.429066Z"}},"outputs":[{"name":"stdout","text":"Saved: /kaggle/working/submission_divergence_only.csv\n   ID     score\n0   1  9.122885\n1   2  9.122717\n2   3  9.119098\n3   4  9.100678\n4   5  9.122392\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"submission.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:12:05.671522Z","iopub.execute_input":"2025-11-19T13:12:05.672093Z","iopub.status.idle":"2025-11-19T13:12:05.694924Z","shell.execute_reply.started":"2025-11-19T13:12:05.672073Z","shell.execute_reply":"2025-11-19T13:12:05.694313Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                ID        score\ncount  3638.000000  3638.000000\nmean   1819.500000     9.119384\nstd    1050.344467     0.006934\nmin       1.000000     9.089155\n25%     910.250000     9.118060\n50%    1819.500000     9.120066\n75%    2728.750000     9.122717\nmax    3638.000000     9.133104","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3638.000000</td>\n      <td>3638.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1819.500000</td>\n      <td>9.119384</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1050.344467</td>\n      <td>0.006934</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>9.089155</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>910.250000</td>\n      <td>9.118060</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1819.500000</td>\n      <td>9.120066</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2728.750000</td>\n      <td>9.122717</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3638.000000</td>\n      <td>9.133104</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"print(\"Topic Divergence — Test Set\")\nprint(\"----------------------------------\")\nprint(\"Shape:\", div_test.shape)\n\nprint(\"\\nFirst 20 values:\")\nprint(div_test[:20])\n\nprint(\"\\nSummary statistics:\")\nprint(pd.Series(div_test).describe())\n\nprint(\"\\nHistogram (rounded):\")\nprint(pd.Series(np.round(div_test, 3)).value_counts().sort_index())\n\ndiv_test.describe()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:13:27.402359Z","iopub.execute_input":"2025-11-19T13:13:27.403091Z","iopub.status.idle":"2025-11-19T13:13:27.435860Z","shell.execute_reply.started":"2025-11-19T13:13:27.403065Z","shell.execute_reply":"2025-11-19T13:13:27.435090Z"}},"outputs":[{"name":"stdout","text":"Topic Divergence — Test Set\n----------------------------------\nShape: (3638,)\n\nFirst 20 values:\n[0.30729687 0.31880486 0.31376982 0.3927331  0.4595837  0.707551\n 0.30869532 0.60051966 0.5009735  0.51938814 0.54840076 0.4415053\n 0.3096547  0.5254268  0.49331784 0.54024184 0.3991598  0.40014017\n 0.37033117 0.26876163]\n\nSummary statistics:\ncount    3.638000e+03\nmean     4.216523e-01\nstd      1.327039e-01\nmin     -2.384186e-07\n25%      3.342464e-01\n50%      4.025587e-01\n75%      4.913008e-01\nmax      1.107813e+00\ndtype: float64\n\nHistogram (rounded):\n-0.000    3\n 0.060    1\n 0.082    1\n 0.090    1\n 0.104    1\n         ..\n 1.033    1\n 1.036    1\n 1.041    1\n 1.071    1\n 1.108    1\nName: count, Length: 616, dtype: int64\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/3000758950.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiv_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdiv_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'describe'"],"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'describe'","output_type":"error"}],"execution_count":24},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\n# -------------------------------------------------------\n# 1. YOU ALREADY HAVE div_test FROM PREVIOUS CELLS\n#    ≤ just print first few to confirm\n# -------------------------------------------------------\n\nprint(\"Example divergence values:\", div_test[:20])\nprint(\"Total test rows:\", len(div_test))\n\n# -------------------------------------------------------\n# 2. Partition divergence into 11 brackets (0–10 classes)\n# -------------------------------------------------------\n\nnum_classes = 11\npercentiles = np.linspace(0, 100, num_classes + 1)  # 12 cut points\ncuts = np.percentile(div_test, percentiles)\n\nprint(\"\\nClass bin borders (percentiles):\")\nfor i in range(len(cuts) - 1):\n    print(f\"Class {i}: {cuts[i]:.4f} → {cuts[i+1]:.4f}\")\n\n# -------------------------------------------------------\n# 3. Assign each test sample a class label based on divergence\n# -------------------------------------------------------\n\nclass_labels = np.digitize(div_test, cuts[1:-1], right=True)   # returns 0..10\n\nprint(\"\\nRaw class distribution:\")\nprint(pd.Series(class_labels).value_counts().sort_index())\n\n# -------------------------------------------------------\n# 4. OPTIONAL: Smooth distribution so each class has similar freq\n# -------------------------------------------------------\n# Why? divergence tends to cluster — so we re-quantize evenly\n\ndef enforce_even_bins(values, n_bins=11):\n    \"\"\"\n    Sorts values and assigns evenly-distributed class labels.\n    Ensures each class has ~len(values)/11 samples.\n    \"\"\"\n    sorted_idx = np.argsort(values)\n    labels = np.zeros(len(values), dtype=int)\n\n    per_bin = len(values) // n_bins\n\n    for cls in range(n_bins):\n        start = cls * per_bin\n        end = (cls + 1) * per_bin if cls < n_bins - 1 else len(values)\n        labels[sorted_idx[start:end]] = cls\n    \n    return labels\n\nbalanced_labels = enforce_even_bins(div_test, num_classes)\n\nprint(\"\\nBalanced class distribution:\")\nprint(pd.Series(balanced_labels).value_counts().sort_index())\n\n# -------------------------------------------------------\n# 5. Convert class label to score (0–10)\n# -------------------------------------------------------\n\nfinal_scores = balanced_labels.astype(float)\n\n# -------------------------------------------------------\n# 6. Save submission.csv\n# -------------------------------------------------------\n\nsubmission = pd.DataFrame({\n    \"ID\": np.arange(1, len(final_scores) + 1),\n    \"score\": final_scores\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\n\nprint(\"\\nCreated submission.csv with balanced divergence-based scores!\")\nprint(submission.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:15:11.021635Z","iopub.execute_input":"2025-11-19T13:15:11.021930Z","iopub.status.idle":"2025-11-19T13:15:11.047361Z","shell.execute_reply.started":"2025-11-19T13:15:11.021908Z","shell.execute_reply":"2025-11-19T13:15:11.046585Z"}},"outputs":[{"name":"stdout","text":"Example divergence values: [0.30729687 0.31880486 0.31376982 0.3927331  0.4595837  0.707551\n 0.30869532 0.60051966 0.5009735  0.51938814 0.54840076 0.4415053\n 0.3096547  0.5254268  0.49331784 0.54024184 0.3991598  0.40014017\n 0.37033117 0.26876163]\nTotal test rows: 3638\n\nClass bin borders (percentiles):\nClass 0: -0.0000 → 0.2686\nClass 1: 0.2686 → 0.3094\nClass 2: 0.3094 → 0.3422\nClass 3: 0.3422 → 0.3657\nClass 4: 0.3657 → 0.3915\nClass 5: 0.3915 → 0.4153\nClass 6: 0.4153 → 0.4448\nClass 7: 0.4448 → 0.4819\nClass 8: 0.4819 → 0.5281\nClass 9: 0.5281 → 0.6067\nClass 10: 0.6067 → 1.1078\n\nRaw class distribution:\n0     331\n1     331\n2     330\n3     331\n4     331\n5     330\n6     331\n7     331\n8     330\n9     331\n10    331\nName: count, dtype: int64\n\nBalanced class distribution:\n0     330\n1     330\n2     330\n3     330\n4     330\n5     330\n6     330\n7     330\n8     330\n9     330\n10    338\nName: count, dtype: int64\n\nCreated submission.csv with balanced divergence-based scores!\n   ID  score\n0   1    1.0\n1   2    2.0\n2   3    2.0\n3   4    5.0\n4   5    7.0\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"submission.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T13:15:28.604182Z","iopub.execute_input":"2025-11-19T13:15:28.604469Z","iopub.status.idle":"2025-11-19T13:15:28.617856Z","shell.execute_reply.started":"2025-11-19T13:15:28.604451Z","shell.execute_reply":"2025-11-19T13:15:28.617157Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"                ID        score\ncount  3638.000000  3638.000000\nmean   1819.500000     5.010995\nstd    1050.344467     3.167905\nmin       1.000000     0.000000\n25%     910.250000     2.000000\n50%    1819.500000     5.000000\n75%    2728.750000     8.000000\nmax    3638.000000    10.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3638.000000</td>\n      <td>3638.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1819.500000</td>\n      <td>5.010995</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>1050.344467</td>\n      <td>3.167905</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>910.250000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1819.500000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2728.750000</td>\n      <td>8.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3638.000000</td>\n      <td>10.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# ============================================\n# CELL 5 — Negative Sampling\n# ============================================\n\ndef apply_random_metric_shuffling(df, metric_list, num_negatives=1):\n    print(f\"Generating {num_negatives} negative samples per row...\")\n    new_rows = []\n    \n    high_df = df[df[\"score\"] >= 8.0]  # only high quality for negative sampling\n    \n    for _, row in tqdm(high_df.iterrows(), total=len(high_df)):\n        current_metric = row[\"metric_name\"]\n        valid_metrics = [m for m in metric_list if m != current_metric]\n\n        if not valid_metrics:\n            continue\n\n        selected = random.sample(valid_metrics, num_negatives)\n\n        for m in selected:\n            nr = row.copy()\n            nr[\"metric_name\"] = m\n\n            # KEY TRICK: wrong metric → score 0\n            nr[\"score\"] = 0.0\n\n            # keep original index for embedding\n            nr[\"orig_index\"] = row[\"orig_index\"]\n\n            new_rows.append(nr)\n\n    df_aug = pd.concat([df, pd.DataFrame(new_rows)], ignore_index=True)\n    df_aug = df_aug.sample(frac=1, random_state=SEED).reset_index(drop=True)\n\n    print(\"Negative samples generated:\", len(new_rows))\n    return df_aug\n\n\ntrain_aug = apply_random_metric_shuffling(train_df, metric_list, num_negatives=1)\n\nprint(\"Augmented shape:\", train_aug.shape)\nprint(train_aug[\"score\"].value_counts().sort_index())\n\nprint(\"Cell 5 complete — augmented dataset created.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:32:10.183249Z","iopub.execute_input":"2025-11-19T12:32:10.183582Z","iopub.status.idle":"2025-11-19T12:32:10.826447Z","shell.execute_reply.started":"2025-11-19T12:32:10.183561Z","shell.execute_reply":"2025-11-19T12:32:10.825809Z"}},"outputs":[{"name":"stdout","text":"Generating 1 negative samples per row...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4825 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf242bfecba44cc2bc8d47f003d19aec"}},"metadata":{}},{"name":"stdout","text":"Negative samples generated: 4825\nAugmented shape: (9825, 7)\nscore\n0.0     4838\n1.0        6\n2.0        5\n3.0        7\n4.0        3\n5.0        1\n6.0       45\n7.0       95\n8.0      259\n9.0     3123\n9.5        1\n10.0    1442\nName: count, dtype: int64\nCell 5 complete — augmented dataset created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# ============================================\n# CELL 6 — Re-align LaBSE Embeddings using orig_index\n# ============================================\n\n# Extract safe mapping\nrow_map = train_aug[\"orig_index\"].values\n\nprint(\"Max orig_index:\", row_map.max())\nprint(\"Embedding matrix rows:\", X_train_labse.shape[0])\n\n# SAFE RE-INDEXING\nX_train_final = X_train_labse[row_map]\ny_final = train_aug[\"score\"].astype(int).values\nmetric_names_final = train_aug[\"metric_name\"].values\n\nprint(\"Final embedding shape:\", X_train_final.shape)\nprint(\"Final labels shape:\", y_final.shape)\n\nprint(\"Cell 6 complete — safe embedding re-alignment successful.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:32:26.578575Z","iopub.execute_input":"2025-11-19T12:32:26.579180Z","iopub.status.idle":"2025-11-19T12:32:26.596645Z","shell.execute_reply.started":"2025-11-19T12:32:26.579157Z","shell.execute_reply":"2025-11-19T12:32:26.595744Z"}},"outputs":[{"name":"stdout","text":"Max orig_index: 4999\nEmbedding matrix rows: 5000\nFinal embedding shape: (9825, 768)\nFinal labels shape: (9825,)\nCell 6 complete — safe embedding re-alignment successful.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ============================================\n# CELL 7 — Topic Divergence Feature\n# ============================================\n\ndef compute_topic_divergence(df, text_col1=\"user_prompt\", text_col2=\"response\"):\n    print(\"Computing divergence embeddings...\")\n    \n    t1 = model.encode(\n        df[text_col1].fillna(\"\").tolist(),\n        batch_size=32,\n        show_progress_bar=True\n    )\n    t2 = model.encode(\n        df[text_col2].fillna(\"\").tolist(),\n        batch_size=32,\n        show_progress_bar=True\n    )\n\n    # Cosine similarity → divergence = 1 - cos\n    cos = cosine_similarity(t1, t2).diagonal()\n    div = 1 - cos\n\n    return div\n\n# Divergence for augmented train and test\ntopic_div_train = compute_topic_divergence(train_aug)\ntopic_div_test  = compute_topic_divergence(test_df)\n\nprint(\"Divergence examples:\", topic_div_train[:10])\nprint(\"Cell 7 complete — topic divergence ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:32:34.170375Z","iopub.execute_input":"2025-11-19T12:32:34.170984Z","iopub.status.idle":"2025-11-19T12:37:54.432276Z","shell.execute_reply.started":"2025-11-19T12:32:34.170959Z","shell.execute_reply":"2025-11-19T12:37:54.431490Z"}},"outputs":[{"name":"stdout","text":"Computing divergence embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/308 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc111fb7e6b948aebe28751e0a15548c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/308 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"842f34d2731f48fa9c8be50999af9c63"}},"metadata":{}},{"name":"stdout","text":"Computing divergence embeddings...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/114 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81e200ce3fd341c0a92638ff191214ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/114 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad9ca3bf562847689fda7dfc6426c83b"}},"metadata":{}},{"name":"stdout","text":"Divergence examples: [0.5457946  0.44151962 0.5220934  0.30910146 0.5443378  0.42945468\n 0.15131378 0.47859347 0.21403229 0.62286836]\nCell 7 complete — topic divergence ready.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ============================================\n# CELL 8 — Prepare Final Model Inputs\n# ============================================\n\n# Map metric_name → embedding index\nmetric_name_to_idx = {name: i for i, name in enumerate(metric_list)}\n\ntrain_metric_idx = np.array([\n    metric_name_to_idx[m] for m in train_aug[\"metric_name\"]\n])\ntest_metric_idx = np.array([\n    metric_name_to_idx[m] for m in test_df[\"metric_name\"]\n])\n\nmetric_emb_train = metric_embeddings[train_metric_idx]\nmetric_emb_test  = metric_embeddings[test_metric_idx]\n\n# Final feature concatenation: [LaBSE | metric_emb | divergence]\nX_train_combo = np.hstack([X_train_final, metric_emb_train, topic_div_train.reshape(-1,1)])\nX_test_combo  = np.hstack([X_test_labse, metric_emb_test, topic_div_test.reshape(-1,1)])\n\nprint(\"X_train_combo shape:\", X_train_combo.shape)\nprint(\"X_test_combo  shape:\", X_test_combo.shape)\n\nprint(\"Cell 8 complete — final model inputs prepared.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:37:54.433508Z","iopub.execute_input":"2025-11-19T12:37:54.433755Z","iopub.status.idle":"2025-11-19T12:37:54.471090Z","shell.execute_reply.started":"2025-11-19T12:37:54.433739Z","shell.execute_reply":"2025-11-19T12:37:54.470385Z"}},"outputs":[{"name":"stdout","text":"X_train_combo shape: (9825, 1537)\nX_test_combo  shape: (3638, 1537)\nCell 8 complete — final model inputs prepared.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# =====================================================\n# TOPIC DIVERGENCE ONLY MODEL\n# =====================================================\n\nprint(\"Preparing Topic Divergence–only model...\")\n\n# 1) Compute divergence (user_prompt vs response)\ndef compute_div(df):\n    e1 = model.encode(df[\"user_prompt\"].fillna(\"\").tolist(),\n                      batch_size=32, show_progress_bar=True)\n    e2 = model.encode(df[\"response\"].fillna(\"\").tolist(),\n                      batch_size=32, show_progress_bar=True)\n    sim = cosine_similarity(e1, e2).diagonal()\n    return 1 - sim   # divergence\n\nprint(\"Computing divergence for train/test...\")\ndiv_train = compute_div(train_df)\ndiv_test  = compute_div(test_df)\n\n# 2) Prepare train matrix\nX_div_train = div_train.reshape(-1, 1)\ny_div_train = train_df[\"score\"].astype(float).values\n\nX_div_test = div_test.reshape(-1, 1)\n\nprint(\"Train divergence shape:\", X_div_train.shape)\nprint(\"Test divergence shape:\", X_div_test.shape)\n\n# 3) Train simple LGBM regression\nparams_div = {\n    \"objective\": \"regression\",\n    \"metric\": \"rmse\",\n    \"learning_rate\": 0.05,\n    \"num_leaves\": 16,\n    \"min_data_in_leaf\": 20,\n    \"feature_fraction\": 1.0,\n    \"verbosity\": -1,\n    \"seed\": 42\n}\n\nprint(\"Training divergence regressor...\")\n\ngkf = GroupKFold(n_splits=5)\ngroups = train_df[\"metric_name\"].values\n\noof_div = np.zeros_like(y_div_train)\ntest_div_pred = np.zeros((len(X_div_test),))\n\nfor fold, (tr, val) in enumerate(gkf.split(X_div_train, y_div_train, groups)):\n    print(f\"\\nFold {fold}\")\n    \n    train_set = lgb.Dataset(X_div_train[tr], y_div_train[tr])\n    val_set   = lgb.Dataset(X_div_train[val], y_div_train[val])\n\n    m = lgb.train(\n        params_div,\n        train_set,\n        num_boost_round=500,\n        valid_sets=[val_set],\n        callbacks=[lgb.early_stopping(50),\n                   lgb.log_evaluation(50)]\n    )\n\n    oof_div[val] = m.predict(X_div_train[val])\n    test_div_pred += m.predict(X_div_test) / gkf.n_splits\n\n# Clip to valid range, round to 1 decimal\noof_div = np.clip(oof_div, 0, 10)\ntest_div_pred = np.clip(test_div_pred, 0, 10)\n\nrmse_div = mean_squared_error(y_div_train, oof_div, squared=False)\nprint(\"\\nTopic Divergence–only RMSE:\", rmse_div)\n\n# 4) Create submission file\nsub_div = pd.DataFrame({\n    \"ID\": np.arange(1, len(test_div_pred) + 1),\n    \"score\": test_div_pred\n})\n\nsub_div_path = \"/kaggle/working/submission_divergence_only.csv\"\nsub_div.to_csv(sub_div_path, index=False)\n\nprint(\"\\nSubmission saved to:\", sub_div_path)\nprint(sub_div.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:54:26.653821Z","iopub.execute_input":"2025-11-19T12:54:26.654244Z","iopub.status.idle":"2025-11-19T12:54:26.698123Z","shell.execute_reply.started":"2025-11-19T12:54:26.654215Z","shell.execute_reply":"2025-11-19T12:54:26.697220Z"}},"outputs":[{"name":"stdout","text":"Preparing Topic Divergence–only model...\nComputing divergence for train/test...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/1500283687.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Computing divergence for train/test...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdiv_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mdiv_test\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcompute_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_48/1500283687.py\u001b[0m in \u001b[0;36mcompute_div\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 1) Compute divergence (user_prompt vs response)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     e1 = model.encode(df[\"user_prompt\"].fillna(\"\").tolist(),\n\u001b[0m\u001b[1;32m     10\u001b[0m                       batch_size=32, show_progress_bar=True)\n\u001b[1;32m     11\u001b[0m     e2 = model.encode(df[\"response\"].fillna(\"\").tolist(),\n","\u001b[0;31mAttributeError\u001b[0m: 'Booster' object has no attribute 'encode'"],"ename":"AttributeError","evalue":"'Booster' object has no attribute 'encode'","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"# ============================================\n# CELL 9 — LightGBM Multiclass Classification (FIXED)\n# ============================================\n\nclasses = np.arange(0, 11)\nnum_classes = len(classes)\n\n# Class counts (after augmentation)\nclass_counts = np.bincount(y_final, minlength=num_classes)\n\n# Inverse frequency weights\nweights = {i: 1 / (class_counts[i] + 1e-6) for i in range(num_classes)}\n\nprint(\"Class counts:\", class_counts)\nprint(\"Class weights:\", weights)\n\nparams = {\n    \"objective\": \"multiclass\",\n    \"metric\": \"multi_logloss\",\n    \"num_class\": num_classes,\n    \"learning_rate\": 0.04,\n    \"num_leaves\": 64,\n    \"feature_fraction\": 0.75,\n    \"bagging_fraction\": 0.7,\n    \"bagging_freq\": 1,\n    \"min_data_in_leaf\": 25,\n    \"lambda_l2\": 0.1,\n    \"seed\": SEED,\n    \"verbosity\": -1\n}\n\ngkf = GroupKFold(n_splits=5)\n\noof_preds = np.zeros((len(y_final), num_classes))\ntest_preds = np.zeros((X_test_combo.shape[0], num_classes))\ngroups = metric_names_final\n\nfold_rmse = []\n\nfor fold, (tr, val) in enumerate(gkf.split(X_train_combo, y_final, groups)):\n    print(f\"\\n=== Fold {fold} ===\")\n\n    X_tr, X_val = X_train_combo[tr], X_train_combo[val]\n    y_tr, y_val = y_final[tr], y_final[val]\n\n    # ---------------------------\n    # FIX: Apply weights per sample\n    # ---------------------------\n    sample_weights = np.array([weights[y] for y in y_tr])\n\n    train_set = lgb.Dataset(X_tr, y_tr, weight=sample_weights)\n    val_set   = lgb.Dataset(X_val, y_val)\n\n    model = lgb.train(\n        params,\n        train_set,\n        num_boost_round=600,\n        valid_sets=[val_set],\n        callbacks=[\n            lgb.early_stopping(50),\n            lgb.log_evaluation(50)\n        ]\n    )\n\n    # Store predictions\n    oof_preds[val] = model.predict(X_val)\n    test_preds += model.predict(X_test_combo) / gkf.n_splits\n\n    # Decode expected value for RMSE\n    val_pred_scores = (oof_preds[val] * classes).sum(axis=1)\n    rmse = mean_squared_error(y_val, val_pred_scores, squared=False)\n    fold_rmse.append(rmse)\n\n    print(f\"Fold {fold} RMSE: {rmse:.4f}\")\n\nprint(\"\\nAverage CV RMSE:\", np.mean(fold_rmse))\nprint(\"Cell 9 complete — LGBM classifier trained with sample weights.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:42:40.020398Z","iopub.execute_input":"2025-11-19T12:42:40.020717Z","iopub.status.idle":"2025-11-19T12:47:44.964816Z","shell.execute_reply.started":"2025-11-19T12:42:40.020696Z","shell.execute_reply":"2025-11-19T12:47:44.963901Z"}},"outputs":[{"name":"stdout","text":"Class counts: [4838    6    5    7    3    1   45   95  259 3124 1442]\nClass weights: {0: 0.00020669698218133588, 1: 0.16666663888889352, 2: 0.199999960000008, 3: 0.1428571224489825, 4: 0.33333322222225925, 5: 0.9999990000010001, 6: 0.022222221728395074, 7: 0.01052631567867036, 8: 0.00386100384609651, 9: 0.00032010243267602354, 10: 0.0006934812755246316}\n\n=== Fold 0 ===\nTraining until validation scores don't improve for 50 rounds\n[50]\tvalid_0's multi_logloss: 1.63774\n[100]\tvalid_0's multi_logloss: 1.43446\n[150]\tvalid_0's multi_logloss: 1.33806\n[200]\tvalid_0's multi_logloss: 1.28454\n[250]\tvalid_0's multi_logloss: 1.25578\n[300]\tvalid_0's multi_logloss: 1.23914\n[350]\tvalid_0's multi_logloss: 1.22996\n[400]\tvalid_0's multi_logloss: 1.22447\n[450]\tvalid_0's multi_logloss: 1.22108\n[500]\tvalid_0's multi_logloss: 1.22064\nEarly stopping, best iteration is:\n[463]\tvalid_0's multi_logloss: 1.22055\nFold 0 RMSE: 4.6972\n\n=== Fold 1 ===\nTraining until validation scores don't improve for 50 rounds\n[50]\tvalid_0's multi_logloss: 1.65123\n[100]\tvalid_0's multi_logloss: 1.43168\n[150]\tvalid_0's multi_logloss: 1.32913\n[200]\tvalid_0's multi_logloss: 1.27425\n[250]\tvalid_0's multi_logloss: 1.24246\n[300]\tvalid_0's multi_logloss: 1.22358\n[350]\tvalid_0's multi_logloss: 1.20966\n[400]\tvalid_0's multi_logloss: 1.20197\n[450]\tvalid_0's multi_logloss: 1.19938\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_48/175191937.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mval_set\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     model = lgb.train(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    320\u001b[0m             )\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_LGBM_BoosterEvalMethodResultType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4153\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot update due to null objective function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m             _safe_call(\n\u001b[0;32m-> 4155\u001b[0;31m                 _LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   4156\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4157\u001b[0m                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_finished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":15},{"cell_type":"code","source":"# ============================================\n# CELL 10 — Topic Divergence Regression Model\n# ============================================\n\nparams_reg = {\n    \"objective\": \"regression\",\n    \"metric\": \"rmse\",\n    \"learning_rate\": 0.04,\n    \"num_leaves\": 31,\n    \"min_data_in_leaf\": 20,\n    \"feature_fraction\": 0.8,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 1,\n    \"verbosity\": -1,\n    \"seed\": SEED\n}\n\noof_reg = np.zeros(len(y_final))\ntest_reg = np.zeros(topic_div_test.shape[0])\n\nfor fold, (tr, val) in enumerate(gkf.split(topic_div_train, y_final, groups)):\n    print(f\"\\n[Reg Fold {fold}]\")\n\n    X_tr, X_val = topic_div_train[tr].reshape(-1,1), topic_div_train[val].reshape(-1,1)\n    y_tr, y_val = y_final[tr], y_final[val]\n\n    dtrain = lgb.Dataset(X_tr, y_tr)\n    dval   = lgb.Dataset(X_val, y_val)\n\n    mreg = lgb.train(\n        params_reg,\n        dtrain,\n        num_boost_round=500,\n        valid_sets=[dval],\n        callbacks=[lgb.early_stopping(30), lgb.log_evaluation(50)]\n    )\n\n    oof_reg[val] = mreg.predict(X_val)\n    test_reg += mreg.predict(topic_div_test.reshape(-1,1)) / gkf.n_splits\n\nrmse_reg = mean_squared_error(y_final, oof_reg, squared=False)\nprint(\"\\nRegressor OOF RMSE:\", rmse_reg)\nprint(\"Cell 10 complete — divergence regressor trained.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T12:37:54.555026Z","iopub.status.idle":"2025-11-19T12:37:54.555358Z","shell.execute_reply.started":"2025-11-19T12:37:54.555185Z","shell.execute_reply":"2025-11-19T12:37:54.555203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 11 — Ensemble final predictions\n# ============================================\n\n# Classifier expected-value prediction\ntest_pred_scores_cls = (test_preds * classes).sum(axis=1)\n\n# Ensemble weights\nW_CLS = 0.85\nW_REG = 0.15\n\ntest_pred_final = (\n    W_CLS * test_pred_scores_cls\n    + W_REG * test_reg\n)\n\n# Clip to valid range\ntest_pred_final = np.clip(test_pred_final, 0, 10)\n\nprint(\"Ensemble preview:\", test_pred_final[:20])\nprint(\"Cell 11 complete — ensemble done.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 12 — OOF Evaluation\n# ============================================\n\n# OOF classifier expected values\noof_cls_scores = (oof_preds * classes).sum(axis=1)\n\n# Final OOF ensemble\noof_final = W_CLS * oof_cls_scores + W_REG * oof_reg\noof_final = np.clip(oof_final, 0, 10)\n\noof_rmse = mean_squared_error(y_final, oof_final, squared=False)\n\nprint(f\"Final OOF RMSE (ensemble): {oof_rmse:.4f}\")\nprint(\"Cell 12 complete — OOF computed.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 13 — Create submission.csv\n# ============================================\n\nsub = pd.DataFrame({\n    \"ID\": np.arange(1, len(test_pred_final) + 1),\n    \"score\": test_pred_final\n})\n\n# Round to 1 decimal to match expected format\nsub[\"score\"] = sub[\"score\"].round(1)\n\nSUB_PATH = \"/kaggle/working/submission.csv\"\nsub.to_csv(SUB_PATH, index=False)\n\nprint(\"Submission file written to:\", SUB_PATH)\nprint(sub.head())\nprint(\"Cell 13 complete — submission generated.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# CELL 14 — Final Summary\n# ============================================\n\nprint(\"==== SUMMARY ====\")\nprint(\"Train rows (augmented):\", train_aug.shape[0])\nprint(\"Original embeddings:\", X_train_labse.shape)\nprint(\"Final training features:\", X_train_combo.shape)\nprint(\"Test rows:\", X_test_combo.shape[0])\n\nprint(\"\\nModel components:\")\nprint(\"- LaBSE Encoder\")\nprint(\"- Metric Embedding\")\nprint(\"- Topic Divergence Feature\")\nprint(\"- LGBM Multiclass Classifier\")\nprint(\"- LGBM Divergence Regressor\")\nprint(\"- Weighted Ensemble\")\n\nprint(\"\\nFinal OOF RMSE:\", oof_rmse)\nprint(\"Submission located at:\", SUB_PATH)\n\nprint(\"\\nNotebook complete.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================\n# IMPORTS\n# ============================================================\nimport numpy as np\nimport pandas as pd\nimport json\nfrom tqdm import tqdm\nfrom sentence_transformers import SentenceTransformer\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\n\n# ============================================================\n# 1. LOAD DATA (JSON)\n# ============================================================\ntrain_path = \"/kaggle/input/da5401-2025-data-challenge/train_data.json\"\ntest_path  = \"/kaggle/input/da5401-2025-data-challenge/test_data.json\"\n\ntrain_df = pd.read_json(train_path, lines=True)\ntest_df  = pd.read_json(test_path,  lines=True)\n\n# Expected columns:\n# system_prompt, user_prompt, response, metric_name, score\n\n\n# ============================================================\n# 2. LOAD METRIC NAME EMBEDDINGS (given)\n# ============================================================\nmetric_emb = np.load(\"/kaggle/input/da5401-2025-data-challenge/metric_name_embeddings.npy\")\n# shape (145, 300)\n\nwith open(\"/kaggle/input/da5401-2025-data-challenge/metric_names.json\") as f:\n    metric_list = json.load(f)\n\nmetric_to_id = {m: i for i, m in enumerate(metric_list)}\n\ntrain_metric_idx = train_df[\"metric_name\"].map(metric_to_id).values\ntest_metric_idx  = test_df[\"metric_name\"].map(metric_to_id).values\n\ntrain_metric_vec = metric_emb[train_metric_idx]   # (n_train, 300)\ntest_metric_vec  = metric_emb[test_metric_idx]    # (n_test, 300)\n\n\n# ============================================================\n# 3. LOAD LaBSE (for system / user / response)\n# ============================================================\nlabse = SentenceTransformer(\"sentence-transformers/LaBSE\")\n\ndef embed(texts):\n    return labse.encode(texts, batch_size=64, show_progress_bar=True)\n\n\n# Encode train\ntrain_df[\"system_prompt\"]  = train_df[\"system_prompt\"].fillna(\"\")\ntrain_df[\"user_prompt\"]    = train_df[\"user_prompt\"].fillna(\"\")\ntrain_df[\"response\"]       = train_df[\"response\"].fillna(\"\")\ntest_df[\"system_prompt\"]   = test_df[\"system_prompt\"].fillna(\"\")\ntest_df[\"user_prompt\"]     = test_df[\"user_prompt\"].fillna(\"\")\ntest_df[\"response\"]        = test_df[\"response\"].fillna(\"\")\n\n# Now embed safely\ntrain_sys_vec  = embed(train_df[\"system_prompt\"].tolist())\ntrain_usr_vec  = embed(train_df[\"user_prompt\"].tolist())\ntrain_resp_vec = embed(train_df[\"response\"].tolist())\n\ntest_sys_vec  = embed(test_df[\"system_prompt\"].tolist())\ntest_usr_vec  = embed(test_df[\"user_prompt\"].tolist())\ntest_resp_vec = embed(test_df[\"response\"].tolist())\n\n\n# Encode test\n#test_sys_vec  = embed(test_df[\"system_prompt\"].tolist())\n#test_usr_vec  = embed(test_df[\"user_prompt\"].tolist())\n#test_resp_vec = embed(test_df[\"response\"].tolist())\n\n\n# ============================================================\n# 4. SYNTHETIC NEGATIVES VIA METRIC-SHUFFLING\n# ============================================================\ndef generate_negative(df, metric_vec):\n    neg_df = df.copy()\n    shuffled = np.random.permutation(len(df))\n    neg_metric_vec = metric_vec[shuffled]\n    neg_df[\"score\"] = np.random.randint(0, 4, size=len(df))  # 0–3 low scores\n    return neg_df, neg_metric_vec\n\nneg_df, neg_metric_vec = generate_negative(train_df, train_metric_vec)\n\n# combine real + synthetic negatives\ntrain_all_df = pd.concat([train_df, neg_df], ignore_index=True)\n\ntrain_metric_full = np.vstack([train_metric_vec, neg_metric_vec])\ntrain_sys_full    = np.vstack([train_sys_vec, train_sys_vec])\ntrain_usr_full    = np.vstack([train_usr_vec, train_usr_vec])\ntrain_resp_full   = np.vstack([train_resp_vec, train_resp_vec])\n\ny_train = np.concatenate([train_df[\"score\"].values, neg_df[\"score\"].values])\n\n\n# ============================================================\n# 5. COSINE SIMILARITY FEATURES\n# ============================================================\ndef cos_sim(a, b):\n    return np.sum(a*b, axis=1) / (np.linalg.norm(a,axis=1) * np.linalg.norm(b,axis=1))\n\ntrain_sim_resp = cos_sim(train_resp_full, train_metric_full).reshape(-1,1)\ntrain_sim_usr  = cos_sim(train_usr_full,  train_metric_full).reshape(-1,1)\ntrain_sim_sys  = cos_sim(train_sys_full,  train_metric_full).reshape(-1,1)\n\ntest_sim_resp = cos_sim(test_resp_vec, test_metric_vec).reshape(-1,1)\ntest_sim_usr  = cos_sim(test_usr_vec,  test_metric_vec).reshape(-1,1)\ntest_sim_sys  = cos_sim(test_sys_vec,  test_metric_vec).reshape(-1,1)\n\n\n# ============================================================\n# 6. BUILD FINAL FEATURE MATRICES\n# ============================================================\n# Dimensions:\n# metric 300d + LaBSE system 768 + user 768 + resp 768 + 3 sims = 2607 dims\n\nX_train = np.hstack([\n    train_metric_full,\n    train_sys_full,\n    train_usr_full,\n    train_resp_full,\n    train_sim_resp,\n    train_sim_usr,\n    train_sim_sys\n])\n\nX_test = np.hstack([\n    test_metric_vec,\n    test_sys_vec,\n    test_usr_vec,\n    test_resp_vec,\n    test_sim_resp,\n    test_sim_usr,\n    test_sim_sys\n])\n\n\n# ============================================================\n# 7. LIGHTGBM TRAINING\n# ============================================================\nparams = {\n    \"objective\": \"regression\",\n    \"metric\": \"rmse\",\n    \"learning_rate\": 0.05,\n    \"num_leaves\": 63,\n    \"max_depth\": 8,\n    \"lambda_l1\": 0.1,\n    \"lambda_l2\": 0.1,\n    \"feature_fraction\": 0.9,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 1,\n    \"verbose\": -1,\n}\n\nX_tr, X_val, y_tr, y_val = train_test_split(\n    X_train, y_train,\n    test_size=0.1,\n    random_state=42\n)\n\ntrain_lgb = lgb.Dataset(X_tr, label=y_tr)\nval_lgb   = lgb.Dataset(X_val, label=y_val)\n\nmodel = lgb.train(\n    params,\n    train_lgb,\n    num_boost_round=2500,\n    valid_sets=[train_lgb, val_lgb],\n    valid_names=[\"train\", \"val\"],\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=100),\n        lgb.log_evaluation(150)\n    ]\n)\n\n\n# ============================================================\n# 8. PREDICTION + SAVE\n# ============================================================\npreds = model.predict(X_test, num_iteration=model.best_iteration)\npreds = preds.clip(0, 10)\n\nout = pd.DataFrame({\n    \"ID\": test_df[\"ID\"],\n    \"score\": preds\n})\n\nout.to_csv(\"submission_labse_metricembed.csv\", index=False)\nprint(\"Saved submission_labse_metricembed.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}